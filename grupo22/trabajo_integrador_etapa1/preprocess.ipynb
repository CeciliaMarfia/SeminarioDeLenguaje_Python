{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "En el dataset de Aeropuertos (A), se debe generar una columna llamada **'elevation_name'** que contenga datos cualitativos indicando la elevación de cada aeropuerto. Esta columna se completará con las palabras: \"bajo\", \"medio\" o \"alto\", según la elevación de cada aeropuerto. Para definir estos grupos, se utilizarán los siguientes valores:\n",
    "\n",
    "* bajo: aeropuertos con elevación menor o igual a 131 ft.\n",
    "* medio: aeropuertos con elevación mayor que 131 ft y menor o igual a 903 ft.\n",
    "* altos: aeropuertos con elevación mayor a 903 ft.\n",
    "\n",
    "Además, se realizará otra modificación en este dataset, consistente en agregar una columna llamada **'prov_name'**, donde se incluirá el nombre de la provincia correspondiente a cada aeropuerto. Esta información se obtendrá consultando los nombres de las ciudades en el dataset (E)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from paths import AR_DATA, AR_AIRPORTS_DATA, AR_AIRPORTS_COPY_DATA\n",
    "from preprocess_functions import classify_elevation, sanitize_text\n",
    "\n",
    "# Abrir el archivo de entrada y el archivo de salida\n",
    "infile_AR = open(AR_DATA, 'r', encoding='utf-8') \n",
    "infile_AR_AIRPORTS = open(AR_AIRPORTS_DATA, 'r', encoding='utf-8') \n",
    "reader_AR = csv.DictReader(infile_AR)\n",
    "data_AR = list(reader_AR)\n",
    "reader_AR_AIRPORTS = csv.DictReader(infile_AR_AIRPORTS)\n",
    "with open(AR_AIRPORTS_COPY_DATA, 'w', newline='', encoding='utf-8') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=reader_AR_AIRPORTS.fieldnames + ['elevation_name', 'prov_name'])\n",
    "    writer.writeheader()\n",
    "            \n",
    "    for row in reader_AR_AIRPORTS:\n",
    "       \n",
    "        elevation_name = classify_elevation(row)\n",
    "        \n",
    "        prov_name = \"\"\n",
    "       \n",
    "        for row_AR in data_AR:\n",
    "            value_municipality = sanitize_text(row[\"municipality\"])\n",
    "            value_city = sanitize_text(row_AR[\"city\"])\n",
    "            if (value_municipality == value_city):\n",
    "                prov_name = row_AR[\"admin_name\"]\n",
    "                break\n",
    "            else:\n",
    "                if row[\"region_name\"] != \"\":\n",
    "                    prov_name = row[\"region_name\"].replace(' Province', '')\n",
    "                else:\n",
    "                    prov_name = \"no_data\"\n",
    "        \n",
    "        # Escribir la fila procesada en el archivo de salida\n",
    "        row['elevation_name'] = elevation_name\n",
    "        row['prov_name'] = prov_name\n",
    "        writer.writerow(row)\n",
    "infile_AR.close()\n",
    "infile_AR_AIRPORTS.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "En el dataset de Conectividad (B), se **realizará un reemplazo** en las celdas que contengan el carácter '-' con la palabra 'NO'. Para el mismo dataset se debe generar una nueva columna denominada **'posee_conectividad'**, la misma puede tomar uno de dos valores posibles: SÍ o NO.\n",
    "\n",
    "El valor será NO si todos los campos ADSL, CABLEMODEM, DIALUP, FIBRAOPTICA, SATELITAL, WIRELESS, TELEFONIAFIJA, 3G y 4G poseen el valor --. Caso contrario el valor será SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from paths import CONECTIVIDAD_DATA, CONECTIVIDAD_COPY_DATA \n",
    "\n",
    "with open(CONECTIVIDAD_DATA, 'r', newline='', encoding='utf-8') as infile, open(CONECTIVIDAD_COPY_DATA, 'w', newline='', encoding='utf-8') as outfile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        fieldnames = reader.fieldnames + ['posee_conectividad']\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in reader:\n",
    "            # Reemplazar '--' con 'NO' en campos relevantes\n",
    "            for field in ['ADSL', 'CABLEMODEM', 'DIALUP', 'FIBRAOPTICA', 'SATELITAL', 'WIRELESS', 'TELEFONIAFIJA', '3G', '4G']:\n",
    "                if row[field] == '--':\n",
    "                    row[field] = 'NO'\n",
    "            \n",
    "            # Determinar el valor de 'posee_conectividad'\n",
    "            if all(row[field] == 'NO' for field in ['ADSL', 'CABLEMODEM', 'DIALUP', 'FIBRAOPTICA', 'SATELITAL', 'WIRELESS', 'TELEFONIAFIJA', '3G', '4G']):\n",
    "                row['posee_conectividad'] = 'NO'\n",
    "            else:\n",
    "                row['posee_conectividad'] = 'SI'\n",
    "            \n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "En el dataset de Lagos (C), se creará una nueva columna llamada **'Sup Tamaño'** que contendrá datos cualitativos indicando el tamaño de cada lago en función de su superficie en kilómetros cuadrados (km²). Esta columna se completará con las palabras: \"chico\", \"medio\" o \"grande\", según los siguientes criterios:\n",
    "\n",
    "* Lagos con una superficie menor o igual a 17 km² serán clasificados como\n",
    "\"chico\".\n",
    "* Lagos con una superficie mayor que 17 km² y menor o igual a 59 km² serán\n",
    "clasificados como \"medio\".\n",
    "* Lagos con una superficie mayor a 59 km² serán clasificados como \"grande\".\n",
    "\n",
    "Además de transformar el campo de coordenadas actual, que sigue el formato estándar de grados, minutos y segundos (GMS), por ejemplo, 42°9'3\"S 71°38'59\"O, en dos campos separados para la latitud y longitud, añade dos nuevos campos para representar la latitud y longitud en formato de grados decimales (GD). Asegúrate de proporcionar la conversión correcta de GMS a GD para ambos campos. En el ejemplo mencionado el valor resultante debería ser -42.150833 para la latitud y -71.649722 para la longitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from paths import LAGOS_DATA, LAGOS_COPY_DATA\n",
    "from preprocess_functions import classify_size\n",
    "from preprocess_functions import convert_gms_to_gd\n",
    "    \n",
    "with open(LAGOS_DATA, 'r', newline='', encoding='utf-8') as infile, open(LAGOS_COPY_DATA, 'w', newline='', encoding='utf-8') as outfile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        fieldnames = reader.fieldnames + ['Sup Tamaño', 'Latitud GD', 'Longitud GD']\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in reader:\n",
    "\n",
    "            # Obtener la superficie del lago del campo 'superficie' como float\n",
    "            superficie_km2 = float(row['Superficie (km²)'])\n",
    "            # Categorizar el tamaño del lago\n",
    "            lake_size = classify_size(superficie_km2)\n",
    "            # Agregar la nueva columna 'Sup Tamaño' al diccionario de la fila\n",
    "            row['Sup Tamaño'] = lake_size\n",
    "\n",
    "            # Convertir coordenadas de GMS a GD para latitud\n",
    "            latitude_gd = convert_gms_to_gd(row['Coordenadas'].split()[0])\n",
    "            row['Latitud GD'] = latitude_gd\n",
    "\n",
    "            # Convertir coordenadas de GMS a GD para longitud\n",
    "            longitude_gd = convert_gms_to_gd(row['Coordenadas'].split()[1])\n",
    "            row['Longitud GD'] = longitude_gd\n",
    "            \n",
    "            # Escribir la fila en el archivo de salida\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Para el dataset de Población del censo 2022 (D) reemplazar los valores \"///\" y \"-\" por cero en los campos que corresponda.\n",
    "\n",
    "Además agregar un nuevo campo que tenga el porcentaje de población en situación de calle. Tener en cuenta el total general (NO tener en cuenta los totales por sexo registrado al nacer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from paths import C2022_RESUMEN_DATA, C2022_RESUMEN_COPY_DATA\n",
    "from preprocess_functions import replace_invalid_values\n",
    "from preprocess_functions import calculate_porcentaje_situacion_calle\n",
    "\n",
    "# Abrir el archivo de entrada y crear el archivo de salida\n",
    "with open(C2022_RESUMEN_DATA, 'r', encoding='utf-8') as infile, open(C2022_RESUMEN_COPY_DATA, 'w', newline='', encoding='utf-8') as outfile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = reader.fieldnames + ['Porcentaje Población en Situación de Calle']\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Procesar cada fila del archivo de entrada\n",
    "    for row in reader:\n",
    "        # Reemplazar los valores inválidos en cada campo\n",
    "        for field in row:\n",
    "            row[field] = replace_invalid_values(row[field])\n",
    "        # Calcular el porcentaje de población en situación de calle\n",
    "        percentage_homeless = calculate_porcentaje_situacion_calle(row)\n",
    "        row['Porcentaje Población en Situación de Calle'] = percentage_homeless\n",
    "\n",
    "        # Escribir la fila modificada en el archivo de salida\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('captum')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "27cd8888c451505594cd6ce93183113956b3735aa05f73d7c3cf078349bc9fda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
