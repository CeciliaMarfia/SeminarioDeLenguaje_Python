{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ejercicio 5 - Práctica 2**\n",
    "5. Para la aceptación de un artículo en un congreso se definen las siguientes\n",
    "especificaciones que deben cumplir y recomendaciones de escritura:\n",
    "título:\n",
    "10 palabras como máximo\n",
    "cada oración del resumen:\n",
    "hasta 12 palabras: fácil de leer\n",
    "entre 13-17 palabras: aceptable para leer entre 18-25 palabras: difícil de leer\n",
    "mas de 25 palabras: muy difícil\n",
    "Es importante destacar que los números no se consideran palabras al momento del análisis por su facilidad de lectura.\n",
    "Dado un artículo en formato string, defina si cumple las especificaciones del título y cuántas oraciones tiene de cada categoría. El formato estándar en que recibe el string tiene la siguiente forma:\n",
    "Ingresá una palabra: mundo\n",
    "No hay letras a.\n",
    "article = \"\"\" título: Experiences in Developing a Distributed Agent-\n",
    "based Modeling Toolkit with Python Version 3\n",
    "resumen: Distributed agent-based modeling (ABM) on high-performance\n",
    "computing resources provides the promise of capturing unprecedented\n",
    "details of large-scale complex systems. However, the specialized\n",
    "knowledge required for developing such ABMs creates barriers to wider\n",
    "adoption and utilization. Here we present our experiences in\n",
    "developing an initial implementation of Repast4Py, a Python-based\n",
    "distributed ABM toolkit. We build on our experiences in developing ABM\n",
    "toolkits, including Repast for High Performance Computing (Repast\n",
    "HPC), to identify the key elements of a useful distributed ABM\n",
    "toolkit. We leverage the Numba, NumPy, and PyTorch packages and the\n",
    " Python C-API to create a scalable modeling system that can exploit the\n",
    "largest HPC resources and emerging computing architectures. \"\"\"\n",
    "En este ejemplo se debe informar: título: not ok\n",
    "Cantidad de oraciones fáciles de leer: 1, aceptables para leer: 2, dificil de leer: 1, muy difícil de leer: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este fragmento de código se separa el título del resumen del artículo.\n",
    "\n",
    "title_index = article.find(\"título:\") + len(\"título:\"): Busca la posición donde comienza la cadena \"título:\" dentro del artículo (article). Luego, añade la longitud de la cadena \"título:\" para encontrar la posición donde termina la etiqueta del título y comienza el texto del título en sí.\n",
    "\n",
    "title_end = article.find(\"resumen:\"): Busca la posición donde comienza la cadena \"resumen:\" dentro del artículo. Esta posición marca el final del título y el comienzo del resumen.\n",
    "\n",
    "title = article[title_index:title_end].strip(): Utilizando las posiciones encontradas, se extrae el texto correspondiente al título del artículo utilizando slicing en la cadena article. El método strip() elimina cualquier espacio en blanco adicional al principio y al final del texto del título."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\" título: Experiences in Developing a Distributed Agent-\n",
    "based Modeling Toolkit with Python Version 3\n",
    "resumen: Distributed agent-based modeling (ABM) on high-performance\n",
    "computing resources provides the promise of capturing unprecedented\n",
    "details of large-scale complex systems. However, the specialized\n",
    "knowledge required for developing such ABMs creates barriers to wider\n",
    "adoption and utilization. Here we present our experiences in\n",
    "developing an initial implementation of Repast4Py, a Python-based\n",
    "distributed ABM toolkit. We build on our experiences in developing ABM\n",
    "toolkits, including Repast for High Performance Computing (Repast\n",
    "HPC), to identify the key elements of a useful distributed ABM\n",
    "toolkit. We leverage the Numba, NumPy, and PyTorch packages and the\n",
    " Python C-API to create a scalable modeling system that can exploit the\n",
    "largest HPC resources and emerging computing architectures. \"\"\"\n",
    "\n",
    "# Separar el título y el resumen, esto lo obtuve con chatGPT\n",
    "title_index = article.find(\"título:\") + len(\"título:\")\n",
    "title_end = article.find(\"resumen:\")\n",
    "title = article[title_index:title_end].strip()\n",
    "\n",
    "summary_index = article.find(\"resumen:\") + len(\"resumen:\")\n",
    "summary = article[summary_index:].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separo la palabras del título y las almaceno en una lista, luego voy sumando y almacenando en la varaible \"title_word_count\" aquellas palabras que no contengan número."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "title_words = title.split()\n",
    "title_word_count = sum(1 for word in title.split() if word.isalnum())\n",
    "print(title_word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializo los contadores para luego categorizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_to_read = 0\n",
    "acceptable_to_read = 0\n",
    "difficult_to_read = 0\n",
    "very_difficult_to_read = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a buscar cada vez que encuentre un caracter de tipo punto (\".\") para determinar que es una oración (sentence), verificar que no contenga un número y luego clasificarla según las variables que acabo de determinar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = summary.split(\".\")\n",
    "for sentence in sentences:\n",
    "    words = sentence.split()\n",
    "    word_count = len([word for word in words if word.isalnum()])\n",
    "    if word_count <= 12:\n",
    "        easy_to_read += 1\n",
    "    elif 13 <= word_count <= 17:\n",
    "        acceptable_to_read += 1\n",
    "    elif 18 <= word_count <= 25:\n",
    "        difficult_to_read += 1\n",
    "    else:\n",
    "        very_difficult_to_read += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora imprimo los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título: not ok\n",
      "Cantidad de oraciones fáciles de leer: 93\n",
      "Cantidad de oraciones aceptables para leer: 3\n",
      "Cantidad de oraciones difíciles de leer: 0\n",
      "Cantidad de oraciones muy difíciles de leer: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Título: {'ok' if title_word_count <= 10 else 'not ok'}\")\n",
    "print(f\"Cantidad de oraciones fáciles de leer: {easy_to_read}\")\n",
    "print(f\"Cantidad de oraciones aceptables para leer: {acceptable_to_read}\")\n",
    "print(f\"Cantidad de oraciones difíciles de leer: {difficult_to_read}\")\n",
    "print(f\"Cantidad de oraciones muy difíciles de leer: {very_difficult_to_read}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
